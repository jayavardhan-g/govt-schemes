"""
Database seeding module for initial scheme data population.

Loads scraped scheme data from parser output and inserts into PostgreSQL
with generated eligibility rules using RuleParser.
"""

import os
import sys
import importlib.util
from db import db
from models import Scheme, SchemeRule
from rule_parser import RuleParser

def load_scraped_schemes():
    """
    Dynamically import parsed schemes from output/sample_schemes.py
    This file is generated by parser.py during the scraping pipeline.
    """
    # Find the output file inside webapp directory
    current_dir = os.path.dirname(os.path.abspath(__file__))
    output_file_path = os.path.join(current_dir, 'output', 'sample_schemes.py')

    if not os.path.exists(output_file_path):
        print(f"Warning: Scraped data file not found at {output_file_path}")
        print("Please run 'runner.py' inside the webapp folder first.")
        # # DEBUG: Log missing file
        # print(f"[DEBUG] Expected path: {output_file_path}")
        return []

    try:
        # Dynamically load the Python module from file path
        spec = importlib.util.spec_from_file_location("scraped_data", output_file_path)
        scraped_module = importlib.util.module_from_spec(spec)
        spec.loader.exec_module(scraped_module)
        
        if hasattr(scraped_module, 'SAMPLE_SCHEMES'):
            schemes = scraped_module.SAMPLE_SCHEMES
            # # DEBUG: Log loaded schemes
            # print(f"[DEBUG] Successfully loaded {len(schemes)} scraped schemes")
            return schemes
        else:
            print("Error: SAMPLE_SCHEMES list not found in the generated file.")
            return []
    except Exception as e:
        print(f"Error loading scraped data: {e}")
        # # DEBUG: Detailed error logging
        # print(f"[DEBUG] Import failed with exception: {e}")
        return []

def ensure_sample_data():
    """
    Main seeding function:
    1. Check if DB already populated (skip if so)
    2. Load scraped data from output file
    3. Generate rules using NLP parser
    4. Insert schemes and rules into database
    """
    
    # Safety check: if DB already has data, skip seeding
    if Scheme.query.count() > 0:
        # # DEBUG: Log skipped seeding
        # print("[DEBUG] Database already populated, skipping seed")
        return

    print("--- Starting Data Seeding ---")
    
    # Load the raw data generated by runner.py -> parser.py
    raw_inputs = load_scraped_schemes()
    
    if not raw_inputs:
        print("No data found to insert.")
        return

    # Initialize NLP-based eligibility rule generator
    parser = RuleParser()
    
    count = 0
    for item in raw_inputs:
        title = item.get('title', 'Unknown Scheme')
        # Eligibility text extracted from HTML by parser
        raw_text = item.get('description', '') 
        source_url = item.get('source_url', '')
        # State detected by parser (may be refined by rule parser)
        scraped_state = item.get('state', '')

        # Skip entries without meaningful eligibility text
        if not raw_text or len(raw_text) < 10:
            # # DEBUG: Log skipped entries
            # print(f"[DEBUG] Skipping '{title}': insufficient description ({len(raw_text)} chars)")
            print(f"Skipping '{title}': Insufficient description text for parsing.")
            continue

        print(f"Processing: {title}...")

        # Generate JSON rule structure from eligibility text
        # parser.parse_text returns (rule_structure, confidence_score)
        rule_json, confidence = parser.parse_text(raw_text)

        # Determine state from parsed rules or use scraped value
        detected_state = scraped_state
        
        # Check if rule parser found explicit state requirement
        for rule in rule_json.get('all', []):
            if rule.get('field') == 'state' and rule.get('op') == 'in':
                if rule.get('value'):
                    # Capitalize state name properly
                    detected_state = rule['value'][0].title() 
                    break

        # Create Scheme record
        scheme = Scheme(
            title=title,
            description=raw_text, # Store full eligibility text
            state=detected_state, 
            source_url=source_url
        )
        
        db.session.add(scheme)
        db.session.flush() # Generate ID for foreign key

        # Create corresponding Rule record
        scheme_rule = SchemeRule(
            scheme_id=scheme.id,
            rule_json=rule_json,
            snippet=raw_text[:500], # Save excerpt for admin reference
            parser_confidence=confidence,
            verified=False # Mark for admin review
        )
        db.session.add(scheme_rule)
        count += 1
        # # DEBUG: Log each insertion
        # print(f"[DEBUG] Added scheme {scheme.id}: {title}")

    # Commit all changes
    db.session.commit()
    print(f"--- Successfully Inserted {count} Schemes ---")