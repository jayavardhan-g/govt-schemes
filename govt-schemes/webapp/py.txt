import base64
import json
from flask import Flask, render_template, request, redirect, url_for, session, jsonify, flash
import os
import traceback
from functools import wraps
from dotenv import load_dotenv
from werkzeug.security import generate_password_hash, check_password_hash
from datetime import datetime

load_dotenv()

from db import init_db, db
from sample_data import ensure_sample_data
from matcher import evaluate_rules_for_profile, evaluate_rule, evaluate_rule_with_details

from models import Scheme, SchemeRule, UserProfile, MatchResult

app = Flask(__name__)
app.secret_key = os.getenv("FLASK_SECRET", "dev-secret-for-demo")

init_db(app)
with app.app_context():
    ensure_sample_data()

idian_states = [
    "Andhra Pradesh","Arunachal Pradesh","Assam","Bihar","Chhattisgarh","Goa",
    "Gujarat","Haryana","Himachal Pradesh","Jharkhand","Karnataka","Kerala",
    "Madhya Pradesh","Maharashtra","Manipur","Meghalaya","Mizoram","Nagaland",
    "Odisha","Punjab","Rajasthan","Sikkim","Tamil Nadu","Telangana","Tripura",
    "Uttar Pradesh","Uttarakhand","West Bengal",
    "Andaman and Nicobar Islands","Chandigarh","Dadra and Nagar Haveli and Daman and Diu",
    "Delhi","Jammu and Kashmir","Ladakh","Lakshadweep","Puducherry"
]

caste_cat = [
    "General/Unreserved",
    "Other Backward Classes (OBC)",
    "Scheduled Caste (SC)",
    "Scheduled Tribe (ST)",
    "Economically Weaker Section (EWS)",
    "Other / Prefer not to say"
]

def _to_int_or_none(v):
    try:
        if v is None or v == '': 
            return None
        return int(v)
    except ValueError: 
        return None

def _to_float_or_none(v):
    try:
        if v is None or v == '': 
            return None
        return float(v)
    except ValueError: 
        return None

def extract_profile_from_form(req_form):
    profile = {
        'age': _to_int_or_none(req_form.get('age')),
        'income': _to_float_or_none(req_form.get('income')),
        'gender': (req_form.get('gender') or None),
        'state': (req_form.get('state') or None),
        'occupation': (req_form.get('occupation') or None),
        'caste': (req_form.get('caste') or None),
        'disability': (req_form.get('disability') or None),
        'household_size': _to_int_or_none(req_form.get('household_size')) or 1
    }
    return profile

@app.route('/')
def index():
    if request.args.get('mode') == 'manual':
        return render_template('index.html', 
                               states=idian_states, 
                               castes=caste_cat,
                               manual_mode=True)

    user_id = session.get('user_id')
    
    if user_id:
        user = UserProfile.query.get(user_id)
        
        if user and user.profile:
            session['profile'] = user.profile 

            results = evaluate_rules_for_profile(user.profile)
            return render_template('results.html', 
                                   results=results, 
                                   profile=user.profile, 
                                   is_dashboard=True)
        else:
            flash("Welcome! Please complete your profile to see eligible schemes.")
            return redirect(url_for('profile'))

    return render_template('index.html', states=idian_states, castes=caste_cat)


@app.route('/results')
def results():
    profile = {}
    is_dashboard = False
    
    encoded_data = request.args.get('data')
    if encoded_data:
        try:
            json_str = base64.urlsafe_b64decode(encoded_data).decode()
            profile = json.loads(json_str)
        except Exception as e:
            profile = {}

    elif session.get('user_id'):
        user = UserProfile.query.get(session['user_id'])
        if user and user.profile:
            profile = user.profile
            is_dashboard = True
    if profile:
        results = evaluate_rules_for_profile(profile)
    else:
        results = []

    return render_template('results.html', 
                           results=results, 
                           profile=profile, 
                           is_dashboard=is_dashboard)

@app.route('/profile', methods=['GET', 'POST'])
def profile():
    if not session.get('user_id'):
        flash('Please login to edit your profile')
        return redirect(url_for('login'))
    
    user = UserProfile.query.get(session['user_id'])
    
    if user is None:
        session.pop('user_id', None)
        flash('Session expired or invalid. Please login again.')
        return redirect(url_for('login'))
    
    if request.method == 'POST':
        new_profile_data = extract_profile_from_form(request.form)
        user.profile = new_profile_data
        db.session.commit()
        flash('Profile updated successfully!')
        return redirect(url_for('index'))
        
    return render_template('profile.html', 
                           user=user, 
                           states=idian_states, 
                           castes=caste_cat)


@app.route('/signup', methods=['GET','POST'])
def signup():
    if request.method == 'POST':
        name = request.form.get('name')
        email = request.form.get('email')
        password = request.form.get('password')
        phone = request.form.get('phone')

        if not email or not password:
            flash('Email and password are required')
            return redirect(url_for('signup'))

        existing = UserProfile.query.filter_by(email=email).first()
        if existing:
            flash('An account with that email already exists')
            return redirect(url_for('signup'))

        pw_hash = generate_password_hash(password)
        user = UserProfile(email=email, password_hash=pw_hash, name=name, phone=phone, profile={})
        db.session.add(user)
        db.session.commit()
        
        session['user_id'] = user.id
        
        flash('Account created! Please fill in your details to get started.')
        return redirect(url_for('profile'))
        
    return render_template('signup.html')


@app.route('/login', methods=['GET','POST'])
def login():
    if request.method == 'POST':
        email = request.form.get('email')
        password = request.form.get('password')
        
        if not email or not password:
            flash('Email and password required')
            return redirect(url_for('login'))
        
        user = UserProfile.query.filter_by(email=email).first()
        if not user or not user.password_hash:
            flash('Invalid credentials')
            return redirect(url_for('login'))
        
        if not check_password_hash(user.password_hash, password):
            flash('Invalid credentials')
            return redirect(url_for('login'))
        
        session['user_id'] = user.id
        flash('Logged in')
        return redirect(url_for('index'))
    
    return render_template('login.html')


@app.route('/logout')
def logout():
    session.pop('user_id', None)
    flash('Logged out')
    return redirect(url_for('index'))

@app.route('/match', methods=['POST'])
def match():
    profile = extract_profile_from_form(request.form)
    is_manual_check = request.form.get('is_manual_check') == '1'

    if session.get('user_id') and not is_manual_check:
        user = UserProfile.query.get(session['user_id'])
        if user:
            user.profile = profile
            db.session.commit()
        return redirect(url_for('results'))

    profile_json = json.dumps(profile)
    profile_b64 = base64.urlsafe_b64encode(profile_json.encode()).decode()
    
    return redirect(url_for('results', data=profile_b64))

@app.route('/scheme/<int:scheme_id>')
def scheme_detail(scheme_id):
    s = Scheme.query.get(scheme_id)
    if not s:
        return 'Scheme not found', 404

    rules = SchemeRule.query.filter_by(scheme_id=scheme_id).all()

    scheme_data = {
        'id': s.id,
        'title': s.title,
        'description': s.description,
        'source_url': s.source_url
    }

    snippet = None
    rule_json = None
    confidence = None
    if rules:
        r0 = rules[0]
        snippet = getattr(r0, 'snippet', '') or ''
        rule_json = r0.rule_json
        confidence = getattr(r0, 'parser_confidence', None)

    profile = session.get('profile')

    evaluation = None
    evaluation_details = []
    try:
        if profile and rules:
            for r in rules:
                rule_obj = r.rule_json
                passed, score, details = evaluate_rule_with_details(rule_obj, profile)
                score_pct = round(float(score) * 100.0, 2)
                
                failed_any = any(d.get('status') is False for d in details)
                skipped_any = any(d.get('skipped') for d in details)
                
                if failed_any:
                    label = 'Not Eligible'
                elif score <= 0:
                    label = 'Not Eligible'
                elif score >= 1.0:
                    label = 'Eligible' if not skipped_any else 'Maybe Eligible'
                else:
                    label = 'Maybe Eligible'

                evaluation_details.append({
                    'rule_id': getattr(r, 'id', None),
                    'score': score_pct,
                    'label': label,
                    'parser_confidence': getattr(r, 'parser_confidence', None),
                    'evaluations': details,
                    'snippet': getattr(r, 'snippet', None)
                })
            
            best = max(evaluation_details, key=lambda x: x['score'])
            evaluation = {
                'label': best['label'],
                'score': best['score'],
                'parser_confidence': best.get('parser_confidence'),
                'snippet': best.get('snippet'),
                'rule_id': best.get('rule_id')
            }
        else:
            evaluation = None
    except Exception as e:
        evaluation = {'error': str(e)}

    skipped_total = 0
    try:
        for det in evaluation_details:
            for ev in det.get('evaluations', []):
                if ev.get('skipped'):
                    skipped_total += 1
    except Exception:
        skipped_total = 0

    pretty_rule = None
    if rule_json:
        try:
            pretty_rule = json.dumps(rule_json, indent=2)
        except:
            pretty_rule = str(rule_json)

    return render_template(
        'scheme.html',
        scheme=scheme_data,
        snippet=snippet,
        rule_json=pretty_rule,
        confidence=confidence,
        evaluation=evaluation,
        evaluation_details=evaluation_details,
        skipped_total=skipped_total
    )

@app.route('/admin/login', methods=['GET','POST'])
def admin_login():
    if request.method == 'POST':
        username = request.form.get('username')
        password = request.form.get('password')
        if username == os.getenv("ADMIN_USER", "admin") and password == os.getenv("ADMIN_PASS", "password"):
            session['admin'] = True
            return redirect(url_for('admin_dashboard'))
        else:
            flash('Invalid credentials')
    return render_template('admin_login.html')

@app.route('/admin/logout')
def admin_logout():
    session.pop('admin', None)
    return redirect(url_for('index'))

@app.route('/admin')
def admin_dashboard():
    if not session.get('admin'):
        return redirect(url_for('admin_login'))

    rows = db.session.query(Scheme, SchemeRule).outerjoin(SchemeRule, Scheme.id==SchemeRule.scheme_id).all()
    schemes = []
    for scheme, rule in rows:
        schemes.append({
            'id': scheme.id,
            'title': scheme.title,
            'confidence': rule.parser_confidence if rule else None,
            'has_rule': bool(rule)
        })
    return render_template('admin_dashboard.html', schemes=schemes)

@app.route('/admin/verify/<int:scheme_id>', methods=['GET','POST'])
def admin_verify(scheme_id):
    if not session.get('admin'):
        return redirect(url_for('admin_login'))

    s = Scheme.query.get(scheme_id)
    if not s:
        return 'Scheme not found', 404

    if request.method == 'POST':
        rule_json = request.form.get('rule_json')
        snippet = request.form.get('snippet')
        try:
            parsed = json.loads(rule_json)
        except Exception as e:
            flash('Invalid JSON: ' + str(e))
            return redirect(url_for('admin_verify', scheme_id=scheme_id))

        existing = SchemeRule.query.filter_by(scheme_id=scheme_id).first()
        if existing:
            existing.rule_json = parsed
            existing.snippet = snippet
            existing.parser_confidence = 1.0
            existing.verified = True
        else:
            newr = SchemeRule(scheme_id=scheme_id, rule_json=parsed, snippet=snippet, parser_confidence=1.0, verified=True)
            db.session.add(newr)
        db.session.commit()
        flash('Saved')
        return redirect(url_for('admin_dashboard'))
    else:
        r = SchemeRule.query.filter_by(scheme_id=scheme_id).first()
        rule_json = json.dumps(r.rule_json, indent=2) if r and r.rule_json else json.dumps({'all': []}, indent=2)
        snippet = r.snippet if r else 'No snippet available (dummy data)'
        return render_template('admin_verify.html', scheme={'id': s.id, 'title': s.title}, rule_json=rule_json, snippet=snippet)

@app.route('/api/stats/schemes_by_state')
def stats_schemes_by_state():
    try:
        from sqlalchemy import func
        rows = db.session.query(Scheme.state, func.count(Scheme.id)).group_by(Scheme.state).all()
        return jsonify([{ 'state': r[0] or 'Unknown', 'count': r[1]} for r in rows])
    except Exception as e:
        app.logger.exception("Error computing stats")
        return jsonify({"error": "Failed to compute stats", "detail": str(e)}), 500

@app.route('/api/scheme/<int:scheme_id>')
def api_scheme(scheme_id):
    s = Scheme.query.get(scheme_id)
    if not s:
        return jsonify({'error':'not found'}), 404
    r = SchemeRule.query.filter_by(scheme_id=scheme_id).first()
    return jsonify({
        'id': s.id,
        'title': s.title,
        'description': s.description,
        'source_url': s.source_url,
        'rule': r.rule_json if r else None,
        'snippet': r.snippet if r else None,
        'confidence': r.parser_confidence if r else None
    })

if __name__ == '__main__':
    app.run(debug=True)import os
from flask_sqlalchemy import SQLAlchemy
from dotenv import load_dotenv

load_dotenv()
db = SQLAlchemy()

def init_db(app):
    db_url = os.getenv("DATABASE_URL")
    print(db_url)
    app.config["SQLALCHEMY_DATABASE_URI"] = db_url
    app.config["SQLALCHEMY_TRACK_MODIFICATIONS"] = False
    db.init_app(app)
    with app.app_context():
        db.create_all()
import csv
import hashlib
import os
import time
from pathlib import Path
from urllib.parse import urlparse

from playwright.sync_api import sync_playwright, TimeoutError as PlaywrightTimeoutError

script_folder = Path(__file__).resolve().parent
seed_csv = script_folder / "seedurls.csv"
OUT_DIR = script_folder / "output" / "raw_html"
OUT_DIR.mkdir(parents=True, exist_ok=True)
NAV_TIMEOUT_MS = 45_000
WAIT_AFTER_NETWORK_IDLE_S = 1.0
MAX_RETRIES = 2
BROWSER_VIEWPORT = {"width": 1280, "height": 900}
USER_AGENT = (
    "Mozilla/5.0 (Windows NT 10.0; Win64; x64) "
    "AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0 Safari/537.36"
)


def url_to_filename(url: str) -> str:
    parsed = urlparse(url)
    domain = parsed.netloc.replace(":", "_")
    path_part = parsed.path.strip("/").replace("/", "_") or "index"
    base = f"{domain}__{path_part}"
    h = hashlib.sha1(url.encode("utf-8")).hexdigest()[:8]

    url_key = "".join(
        c if c.isalnum() or c in ("-", "_", ".") else "_"
        for c in f"{base}__{h}"
    )
    return url_key


def read_seed_urls(csv_path: Path):
    if not csv_path.exists():
        print(f"seedurls.csv not found at: {csv_path}")
        return []

    urls = []
    with open(csv_path, newline="", encoding="utf-8") as f:
        reader = csv.DictReader(f)
        for row in reader:
            if "url" in row and row["url"].strip():
                urls.append(row["url"].strip())
            else:
                first = next(iter(row.values()), "").strip()
                if first:
                    urls.append(first)
    return urls


def scroll_page_slowly(page):
    page.evaluate(
        """() => {
            return new Promise(resolve => {
              const total = document.body.scrollHeight;
              let pos = 0;
              const step = Math.max(Math.floor(total / 8), 200);
              const t = setInterval(() => {
                pos = Math.min(pos + step, total);
                window.scrollTo(0, pos);
                if (pos >= total) {
                  clearInterval(t);
                  setTimeout(resolve, 300);
                }
              }, 150);
            });
        }"""
    )


def fetch_single_page(page, url: str, out_path: Path) -> bool:
    try:
        page.set_viewport_size(BROWSER_VIEWPORT)
        page.set_extra_http_headers({"User-Agent": USER_AGENT})
        page.goto(url, wait_until="networkidle", timeout=NAV_TIMEOUT_MS)

        time.sleep(WAIT_AFTER_NETWORK_IDLE_S)
        try:
            scroll_page_slowly(page)
        except Exception:
            pass

        time.sleep(0.2)

        html = page.content()
        out_path.write_text(html, encoding="utf-8")
        return True

    except PlaywrightTimeoutError as te:
        print(f"[timeout] {url} -> {te}")
        return False

    except Exception as e:
        print(f"[error] {url} -> {e}")
        return False


def main():
    urls = read_seed_urls(seed_csv)
    if not urls:
        print("No URLs found in seedurls.csv")
        return

    print(f"[INFO] Starting fetch of {len(urls)} URLs...")

    with sync_playwright() as p:
        browser = p.chromium.launch(headless=True)
        context = browser.new_context(
            java_script_enabled=True,
            user_agent=USER_AGENT
        )

        try:
            for idx, url in enumerate(urls, start=1):
                print(f"[{idx}/{len(urls)}] Fetching: {url}")
                url_key = url_to_filename(url)
                out_file = OUT_DIR / f"{url_key}.html"

                success = False
                attempt = 0
                while attempt <= MAX_RETRIES and not success:
                    attempt += 1
                    page = context.new_page()

                    try:
                        success = fetch_single_page(page, url, out_file)
                        if success:
                            print(f"  -> saved: {out_file}")
                        else:
                            print(f"  -> attempt {attempt} failed")
                            # Exponential backoff before retry
                            time.sleep(1.5 ** attempt)

                    finally:
                        try:
                            page.close()
                        except Exception:
                            pass

                if not success:
                    print(f"  -> FAILED after {MAX_RETRIES + 1} attempts: {url}")

        finally:
            context.close()
            browser.close()

    print("Fetching complete!")


if __name__ == "__main__":
    main()
import json
from db import db
from models import Scheme, SchemeRule

class MatchingEngine:
    def _safe_cast_number(self, v):
        if v is None: 
            return None
        if isinstance(v, (int, float)): 
            return v
        s = str(v).replace(',', '').strip()
        try:
            if '.' in s: 
                return float(s)
            return int(s)
        except ValueError:
            try: 
                return float(s)
            except ValueError: 
                return None

    def _evaluate_rule(self, profile: dict, rule: dict) -> dict:
        field = rule.get('field')
        op = rule.get('op')
        value = rule.get('value')

        profile_value = profile.get(field)

        if profile_value is None:
            status = None  
            explanation = f"SKIPPED: Profile missing field '{field}'."
            return {
                "rule": f"{field} {op} {value}", 
                "status": None, 
                "profile_value": None, 
                "explanation": explanation, 
                "skipped": True
            }

        if op in (">", "<", ">=", "<="):
            rule_num = self._safe_cast_number(value)
            prof_num = self._safe_cast_number(profile_value)
            
            if rule_num is None or prof_num is None:
                status = False
                explanation = f"FAIL: Non-numeric values for '{field}'."
            else:
                if op == ">": 
                    status = prof_num > rule_num
                elif op == "<": 
                    status = prof_num < rule_num
                elif op == ">=": 
                    status = prof_num >= rule_num
                elif op == "<=": 
                    status = prof_num <= rule_num
                else: 
                    status = False
                explanation = f"{'PASS' if status else 'FAIL'}: {field} ({prof_num}) {op} {rule_num}."
            
            return {
                "rule": f"{field} {op} {value}", 
                "status": status, 
                "profile_value": profile_value, 
                "explanation": explanation, 
                "skipped": False
            }

        if op in ("in", "not_in"):
            if isinstance(profile_value, list):
                prof_values = [str(x).lower() for x in profile_value]
            else:
                prof_values = [str(profile_value).lower()]

            if isinstance(value, list):
                rule_values = [str(x).lower() for x in value]
            else:
                rule_values = [str(value).lower()]

            if op == "in":
                status = any(pv in rule_values for pv in prof_values)
                explanation = f"{'PASS' if status else 'FAIL'}: {field} ({profile_value}) {'is' if status else 'is not'} in required set {value}."
            else:  # not_in
                status = not any(pv in rule_values for pv in prof_values)
                explanation = f"{'PASS' if status else 'FAIL'}: {field} ({profile_value}) exclusion check passed."

            return {
                "rule": f"{field} {op} {value}", 
                "status": status, 
                "profile_value": profile_value, 
                "explanation": explanation, 
                "skipped": False
            }

        if op == "==":
            if isinstance(value, bool):
                status = bool(profile_value) == value
            else:
                status = str(profile_value).lower() == str(value).lower()
            
            explanation = f"{'PASS' if status else 'FAIL'}: {field} matches {value}."
            return {
                "rule": f"{field} {op} {value}", 
                "status": status, 
                "profile_value": profile_value, 
                "explanation": explanation, 
                "skipped": False
            }

        if op == "!=":
            status = str(profile_value).lower() != str(value).lower()
            explanation = f"{'PASS' if status else 'FAIL'}: {field} does not match {value}."
            return {
                "rule": f"{field} {op} {value}", 
                "status": status, 
                "profile_value": profile_value, 
                "explanation": explanation, 
                "skipped": False
            }

        return {
            "rule": f"{field} {op} {value}", 
            "status": False, 
            "profile_value": profile_value, 
            "explanation": f"ERROR: Unknown operator '{op}'", 
            "skipped": False
        }

    def evaluate(self, profile: dict, rule_ast: dict) -> tuple:
        
        if 'any' in rule_ast:
            rules_list = rule_ast.get("any", [])
            mode = 'any' 
        else:
            rules_list = rule_ast.get("all", [])
            mode = 'all' 

        total_rules = len(rules_list)
        passing_rules = 0
        failed_rules = 0  Track explicit rule failures
        outcomes = []

        if total_rules == 0:
            return False, 0.0, [{"error": "Empty rule set"}]

        for r in rules_list:
            out = self._evaluate_rule(profile, r)
            out['atom'] = r 
            out['msg'] = out['explanation']
            outcomes.append(out)
            
            if out['skipped']:
                continue 
            
            if out['status']:
                passing_rules += 1
            else:
                failed_rules += 1

        score = passing_rules / total_rules if total_rules > 0 else 0.0
        
        if mode == 'any':
            final_eligibility = (passing_rules > 0)
        else: 
            final_eligibility = (failed_rules == 0)

        return final_eligibility, score, outcomes

engine = MatchingEngine()

def evaluate_rule_with_details(rule, profile):
    try:
        passed, score, details = engine.evaluate(profile, rule)
        return passed, score, details
    except Exception as e:
        return False, 0.0, [{'error': str(e)}]

def evaluate_rules_for_profile(profile):
    schemes = Scheme.query.order_by(Scheme.title).all()
    results = []

    for s in schemes:
        rules = SchemeRule.query.filter_by(scheme_id=s.id).all()
        best_score = -1.0
        best_passed = False
        best_details = {'note': 'No eligibility rule defined yet'}

        if rules:
            for r in rules:
                try:
                    rule_obj = r.rule_json
                    passed, score, details = evaluate_rule_with_details(rule_obj, profile)
                    if score > best_score:
                        best_score = score
                        best_passed = passed
                        best_details = {
                            'snippet': getattr(r, 'snippet', None),
                            'parser_confidence': getattr(r, 'parser_confidence', None),
                            'rule_id': getattr(r, 'id', None),
                            'evaluations': details
                        }
                except Exception as e:
                    best_details = {'error': str(e)}
        else:
            best_score = 0.0

        if best_score < 0: 
            best_score = 0.0
        
        score_percent = float(best_score) * 100.0

        skipped_any = False
        failed_any = False
        
        if 'evaluations' in best_details and isinstance(best_details['evaluations'], list):
            skipped_any = any(d.get('skipped') for d in best_details['evaluations'])
            failed_any = any(d.get('status') is False for d in best_details['evaluations'])

        if failed_any:
            label = 'Not Eligible'  
        elif best_score >= 1.0:
            label = 'Eligible'  
        elif skipped_any and not failed_any:
            label = 'Maybe Eligible'
        else:
            label = 'Not Eligible'  

        results.append({
            'scheme_id': s.id,
            'title': s.title,
            'description': s.description,
            'result': label,
            'score': round(score_percent, 2),
            'reasons': best_details
        })

    results = sorted(results, key=lambda x: (-x['score'], x['title']))
    return results


def evaluate_rule(rule, profile):
    passed, score, details = evaluate_rule_with_details(rule, profile)
    return bool(passed)
   
def evaluate_rule(rule, profile):
    passed, score, details = evaluate_rule_with_details(rule, profile)
    return bool(passed)from db import db
from datetime import datetime
import json

class Scheme(db.Model):
    __tablename__ = "schemes"
    id = db.Column(db.Integer, primary_key=True)
    title = db.Column(db.String, nullable=False)
    state = db.Column(db.String, nullable=True) 
    description = db.Column(db.Text) 
    source_url = db.Column(db.String)
    last_scraped = db.Column(db.DateTime)
    raw_html_path = db.Column(db.String)

    def to_dict(self):
        return {
            "id": self.id, 
            "title": self.title, 
            "description": self.description,
            "state": self.state,
            "source_url": self.source_url, 
            "last_scraped": self.last_scraped.isoformat() if self.last_scraped else None
        }

class SchemeRule(db.Model):
    __tablename__ = "scheme_rules"
    id = db.Column(db.Integer, primary_key=True)
    scheme_id = db.Column(db.Integer, db.ForeignKey("schemes.id"), nullable=False)
    rule_json = db.Column(db.JSON)
    snippet = db.Column(db.Text) 
    parser_confidence = db.Column(db.Float, default=0.0)
    verified = db.Column(db.Boolean, default=False)

class UserProfile(db.Model):
    __tablename__ = "users"
    id = db.Column(db.Integer, primary_key=True)
    created = db.Column(db.DateTime, default=datetime.utcnow)
    email = db.Column(db.String, unique=True, nullable=True)
    password_hash = db.Column(db.String, nullable=True)
    name = db.Column(db.String, nullable=True)
    phone = db.Column(db.String, nullable=True)
    profile = db.Column(db.JSON)

class MatchResult(db.Model):
    __tablename__ = "matches"
    id = db.Column(db.Integer, primary_key=True)
    user_id = db.Column(db.Integer, db.ForeignKey("users.id"))
    scheme_id = db.Column(db.Integer, db.ForeignKey("schemes.id"))
    result = db.Column(db.String)
    score = db.Column(db.Float)
    reasons = db.Column(db.JSON)
    created = db.Column(db.DateTime, default=datetime.utcnow)import os
import csv
import re
import hashlib
from urllib.parse import urlparse
from bs4 import BeautifulSoup

script_dr = os.path.dirname(os.path.abspath(__file__))
html_save = os.path.join(script_dr, "output", "raw_html")
urlss = os.path.join(script_dr, "seedurls.csv")
op_file = os.path.join(script_dr, "output", "sample_schemes.py")

h_keywords = [
    "eligibility", "eligibility criteria", "who can apply", "who is eligible",
    "conditions for eligibility", "eligible", "applicants"
]

fb_words = [
    "eligible", "not eligible", "income", "annual income", "age", "years", "resident",
    "citizen", "widow", "women", "household", "beneficiary", "ownership", "landholding", "student"
]

states = [
    "Andhra Pradesh","Arunachal Pradesh","Assam","Bihar","Chhattisgarh",
    "Goa","Gujarat","Haryana","Himachal Pradesh","Jharkhand","Karnataka",
    "Kerala","Madhya Pradesh","Maharashtra","Manipur","Meghalaya","Mizoram",
    "Nagaland","Odisha","Punjab","Rajasthan","Sikkim","Tamil Nadu",
    "Telangana","Tripura","Uttar Pradesh","Uttarakhand","West Bengal",
    "Delhi","Jammu and Kashmir","Ladakh"
]


def url_to_filename(url: str) -> str:
    parsed = urlparse(url)
    domain = parsed.netloc.replace(":", "_")
    path_part = parsed.path.strip("/").replace("/", "_") or "index"
    base = f"{domain}__{path_part}"
    h = hashlib.sha1(url.encode("utf-8")).hexdigest()[:8]
    url_key = "".join(c if c.isalnum() or c in ("-", "_", ".") else "_" for c in f"{base}__{h}")
    return url_key


def load_seed_map(csv_path=urlss):
    mapping = {}
    if not os.path.exists(csv_path):
        print(f"Warning: Seed file not found at {csv_path}")
        return mapping
    with open(csv_path, newline="", encoding="utf-8") as f:
        reader = csv.DictReader(f)
        for row in reader:
            # Accept 'url' header or first column fallback
            url = ""
            if "url" in row and row["url"].strip():
                url = row["url"].strip()
            else:
                first = next(iter(row.values()), "").strip()
                if first:
                    url = first
            if url:
                key = url_to_filename(url)
                mapping[key] = url
    return mapping


def read_html(path):
    try:
        with open(path, "r", encoding="utf-8") as f:
            return f.read()
    except Exception:
        return None


def clean_text(s):
    if not s:
        return ""
    s = re.sub(r"\r\n?", "\n", s)
    s = re.sub(r"\u2022|\u2023|\u25E6|\u2043|\u2219", "-", s)
    s = re.sub(r"\n\s*\n+", "\n", s)
    s = re.sub(r"[ \t]+", " ", s)
    return s.strip()


def extract_title(soup, fallback):
    tag = soup.find("title")
    if tag and tag.get_text(strip=True):
        return tag.get_text(strip=True)
    h1 = soup.find(re.compile(r"^h[1-3]$"))
    if h1 and h1.get_text(strip=True):
        return h1.get_text(strip=True)
    return fallback


def find_heading_candidates(soup):
    heads = []
    for level in ["h1", "h2", "h3", "h4", "strong", "b"]:
        for tag in soup.find_all(level):
            txt = tag.get_text(" ", strip=True).lower()
            for kw in h_keywords:
                if kw in txt:
                    heads.append(tag)
                    break
    return heads


def extract_block_after_heading(tag):
    parts = []
    for sib in tag.find_next_siblings():
        if sib.name and re.match(r"h[1-4]", sib.name, re.I):
            break
        if sib.name in ("p", "div", "ul", "ol", "table", "dl"):
            parts.append(sib.get_text("\n", strip=True))
        else:
            t = sib.get_text(" ", strip=True)
            if t:
                parts.append(t)
    return "\n".join(p for p in parts if p)


def fallback_search_for_eligibility(soup):
    candidates = []
    nodes = soup.find_all(["p", "li", "div", "td"])
    for node in nodes:
        txt = node.get_text(" ", strip=True)
        if any(k in txt.lower() for k in fb_words):
            candidates.append(txt)
    if candidates:
        return "\n".join(candidates[:6])
    return ""


def detect_state(text):
    if not text:
        return ""
    for s in states:
        if s.lower() in text.lower():
            return s
    tokens = re.findall(r"\b[A-Za-z]+\b", text)
    for tok in tokens:
        for s in states:
            if tok.lower() == s.split()[0].lower():
                return s
    return ""


def build_entry(title, description, state, source_url):
    return {
        "title": title if title is not None else "",
        "description": description if description is not None else "",
        "state": state if state is not None else "",
        "source_url": source_url if source_url is not None else ""
    }


def write_output_py(entries, out_path=op_file):
    os.makedirs(os.path.dirname(out_path), exist_ok=True)
    with open(out_path, "w", encoding="utf-8") as f:
        f.write("# Auto-generated scheme data from web scraping\n")
        f.write("# # DEBUG: Verify this data looks correct before database import\n")
        f.write("SAMPLE_SCHEMES = [\n")
        for e in entries:
            title = repr(e["title"])
            desc = repr(e["description"])
            state = repr(e["state"])
            src = repr(e["source_url"])
            f.write(f"    {{'title': {title}, 'description': {desc}, 'state': {state}, 'source_url': {src}}},\n")
        f.write("]\n")
    print(f"Wrote {len(entries)} entries to: {out_path}")


def parse_all_html():
    seed_map = load_seed_map()

    if not os.path.isdir(html_save):
        print(f"No raw HTML directory found: {html_save}")
        write_output_py([])
        return

    files = sorted(f for f in os.listdir(html_save) if f.lower().endswith(".html"))
    if not files:
        print("No .html files found under raw_html.")
        write_output_py([])
        return

    entries = []
    for fname in files:
        path = os.path.join(html_save, fname)
        html = read_html(path)
        if not html:
            print(f"[skip] could not read: {fname}")
            continue
        
        soup = BeautifulSoup(html, "html.parser")
        fallback_name = os.path.splitext(fname)[0]
        title = extract_title(soup, fallback_name)

        description = ""
        heading_tags = find_heading_candidates(soup)
        if heading_tags:
            for h in heading_tags:
                blk = extract_block_after_heading(h)
                if blk and len(blk.strip()) > 20:
                    description = blk
                    break

        if not description:
            description = fallback_search_for_eligibility(soup)

        description = clean_text(description)
        state = detect_state(" ".join([title, description]))

        url_key = os.path.splitext(fname)[0]
        source_url = seed_map.get(url_key, "")

        entries.append(build_entry(title=title, description=description, state=state, source_url=source_url))
        print(f"[ok] parsed {fname} -> title: {title} (state='{state}')")

    write_output_py(entries)

if __name__ == "__main__":
    parse_all_html()# routes.py
import os
import json
import traceback
from functools import wraps
from flask import (
    request, jsonify, render_template, redirect, url_for,
    abort, current_app, session
)

from app import app
from db import db
from models import Scheme, SchemeRule, UserProfile, MatchResult

matcher_type = "none"
match_profile = None

try:
    from matcher.engine import match_profile as match_profile_py  # adjust path if needed
    match_profile = match_profile_py
    matcher_type = "python"
    app.logger.info("Matcher integrated: python import")
except Exception:
    MATCHER_HTTP_URL = os.getenv("MATCHER_HTTP_URL", "http://localhost:8000/match")
    matcher_type = "http"
    app.logger.info("Matcher not available via python import; will use HTTP at %s", MATCHER_HTTP_URL)

def check_admin_auth(username, password):
    return username == os.getenv("ADMIN_USER", "admin") and password == os.getenv("ADMIN_PASS", "password")


def require_admin(f):
    @wraps(f)
    def decorated(*args, **kwargs):
        auth = request.authorization
        if not auth or not check_admin_auth(auth.username, auth.password):
            return current_app.make_response(('Could not verify your access level for that URL.\n'
                                              'You have to login with proper credentials', 401,
                                              {'WWW-Authenticate': 'Basic realm="Login Required"'}))
        return f(*args, **kwargs)
    return decorated

@app.route("/", methods=["GET"])
def index():
    return render_template("index.html") if os.path.exists(os.path.join(app.root_path, "templates", "index.html")) else "Gov Schemes - Home"

@app.route("/match", methods=["GET"])
def match_form():
    template_path = os.path.join(app.root_path, "templates", "match_form.html")
    if os.path.exists(template_path):
        return render_template("match_form.html")
    return """
    <h2>Profile Input</h2>
    <form id="p">
      Age: <input name="age"><br>
      Income: <input name="income"><br>
      Gender: <input name="gender"><br>
      State: <input name="state"><br>
      Occupation: <input name="occupation"><br>
      <button type="submit">Submit</button>
    </form>
    <pre id="out"></pre>
    <script>
    document.getElementById('p').onsubmit = async e => {
      e.preventDefault();
      const f = e.target;
      const data = {
        age: Number(f.age.value) || null,
        income: Number(f.income.value) || null,
        gender: f.gender.value || null,
        state: f.state.value || null,
        occupation: f.occupation.value || null
      };
      const res = await fetch('/api/match', {method:'POST', headers:{'Content-Type':'application/json'}, body: JSON.stringify(data)});
      const j = await res.json();
      document.getElementById('out').innerText = JSON.stringify(j, null, 2);
    };
    </script>
    """

@app.route("/api/scheme/<int:scheme_id>", methods=["GET"])
def api_scheme(scheme_id):
    scheme = Scheme.query.get_or_404(scheme_id)
    rules = SchemeRule.query.filter_by(scheme_id=scheme_id).all()
    return jsonify({
        "scheme": scheme.to_dict() if hasattr(scheme, "to_dict") else {
            "id": scheme.id, "title": scheme.title, "description": scheme.description, "source_url": scheme.source_url
        },
        "rules": [
            {
                "id": r.id,
                "rule_json": r.rule_json,
                "snippet": r.snippet,
                "parser_confidence": r.parser_confidence,
                "verified": r.verified
            } for r in rules
        ]
    })


@app.route("/api/match", methods=["POST"])
def api_match():
    try:
        profile = request.get_json(silent=True)
        if not profile or not isinstance(profile, dict):
            return jsonify({"error": "Profile JSON required"}), 400

        user = None
        if session.get('user_id'):
            try:
                user = UserProfile.query.get(session.get('user_id'))
            except Exception:
                user = None
        if user:
            user.profile = profile
            db.session.add(user)
            db.session.commit()
        else:
            user = UserProfile(profile=profile)
            db.session.add(user)
            db.session.commit()
            session['user_id'] = user.id

        results = []
        if matcher_type == "python" and match_profile:
            try:
                results = match_profile(profile)
            except Exception as e:
                app.logger.exception("Matcher (python) failed: %s", e)
                return jsonify({"error": "Internal matcher error", "detail": str(e)}), 500
        else:
            TRY_URL = os.getenv("MATCHER_HTTP_URL", "http://localhost:8000/match")
            try:
                import requests
                resp = requests.post(TRY_URL, json=profile, timeout=15)
                resp.raise_for_status()
                results = resp.json()
            except Exception as e:
                app.logger.exception("Matcher (http) failed: %s", e)
                return jsonify({"error": "Matcher service unavailable", "detail": str(e)}), 502

        if not isinstance(results, list):
            return jsonify({"error": "Invalid matcher response format"}), 502

        saved = []
        for r in results:
            try:
                scheme_id = int(r.get("scheme_id"))
                result_label = r.get("result", "not")
                score = r.get("score")
                reasons = r.get("reasons", {})
                mr = MatchResult(user_id=user.id, scheme_id=scheme_id, result=result_label, score=score, reasons=reasons)
                db.session.add(mr)
                saved.append({
                    "scheme_id": scheme_id,
                    "result": result_label,
                    "score": score,
                    "reasons": reasons
                })
            except Exception:
                app.logger.exception("Failed saving match result: %s", r)
        db.session.commit()

        return jsonify({"user_id": user.id, "results": saved}), 200

    except Exception as e:
        app.logger.exception("Unhandled /api/match error")
        return jsonify({"error": "Internal server error", "detail": str(e)}), 500


@app.route("/api/stats/schemes_by_state", methods=["GET"])
def stats_schemes_by_state():
    try:
        from sqlalchemy import func
        rows = db.session.query(Scheme.source_url, func.count(Scheme.id)).group_by(Scheme.source_url).all()
        return jsonify([{"source_url": r[0], "count": r[1]} for r in rows])
    except Exception as e:
        app.logger.exception("Error computing stats")
        return jsonify({"error": "Failed to compute stats", "detail": str(e)}), 500

@app.route("/admin", methods=["GET"])
@require_admin
def admin_index():
    try:
        pending = SchemeRule.query.filter_by(verified=False).order_by(SchemeRule.parser_confidence.asc()).limit(200).all()
        template_path = os.path.join(app.root_path, "templates", "admin_index.html")
        if os.path.exists(template_path):
            return render_template("admin_index.html", pending=pending)
        html = "<h1>Admin - Pending Rules</h1><ul>"
        for r in pending:
            html += f"<li>Rule #{r.id} (scheme={r.scheme_id}) - confidence={r.parser_confidence} - <a href='{url_for('admin_verify', rule_id=r.id)}'>verify</a></li>"
        html += "</ul>"
        return html
    except Exception as e:
        app.logger.exception("Admin index error")
        return "Admin error", 500


@app.route("/admin/verify/<int:rule_id>", methods=["GET", "POST"])
@require_admin
def admin_verify(rule_id):
    rule = SchemeRule.query.get_or_404(rule_id)
    if request.method == "POST":
        raw = request.form.get("rule_json") or request.get_data(as_text=True)
        if not raw:
            return "No rule_json submitted", 400
        try:
            parsed = json.loads(raw)
        except Exception as e:
            return f"Invalid JSON: {e}", 400
        rule.rule_json = parsed
        rule.verified = True
        db.session.commit()
        return redirect(url_for("admin_index"))
    template_path = os.path.join(app.root_path, "templates", "admin_verify.html")
    if os.path.exists(template_path):
        return render_template("admin_verify.html", rule=rule)
    return f"""
    <h2>Verify Rule #{rule.id} (scheme {rule.scheme_id})</h2>
    <h3>Original snippet</h3>
    <pre>{rule.snippet or ''}</pre>
    <h3>Current JSON</h3>
    <form method="post">
      <textarea name="rule_json" style="width:100%;min-height:300px;">{json.dumps(rule.rule_json or {}, indent=2)}</textarea>
      <br><button type="submit">Save & Verify</button>
    </form>
    """


@app.route("/admin/update_rule", methods=["POST"])
@require_admin
def admin_update_rule():
    try:
        payload = request.get_json(force=True)
        rule_id = payload.get("rule_id")
        new_rule = payload.get("rule_json")
        if not rule_id or new_rule is None:
            return jsonify({"error": "rule_id and rule_json required"}), 400
        rule = SchemeRule.query.get_or_404(rule_id)
        rule.rule_json = new_rule
        rule.verified = True
        if "parser_confidence" in payload:
            try:
                rule.parser_confidence = float(payload["parser_confidence"])
            except Exception:
                pass
        db.session.commit()
        return jsonify({"ok": True, "rule_id": rule.id}), 200
    except Exception as e:
        app.logger.exception("admin_update_rule failed")
        return jsonify({"error": "update failed", "detail": str(e)}), 500


@app.errorhandler(404)
def not_found(e):
    return jsonify({"error": "Not found"}), 404


@app.errorhandler(500)
def internal_err(e):
    tb = traceback.format_exc()
    app.logger.error("Internal error: %s", tb)
    return jsonify({"error": "Internal server error"}), 500
import re
import json
from typing import List

class RuleParser:
    def __init__(self):
        self.INDIAN_JOBS = [
            "farmer", "engineer", "software developer", "doctor", "nurse",
            "teacher", "professor", "student", "labourer", "shopkeeper",
            "manager", "police", "soldier", "army", "government employee",
            "civil servant", "artisan", "fisherman", "driver", "chef",
            "electrician", "plumber", "carpenter", "accountant", "banker",
            "business owner", "entrepreneur", "cleaner", "security guard",
            "architect", "journalist", "photographer", "lawyer", "advocate",
            "researcher", "scientist", "delivery agent", "rickshaw puller",
            "tailor", "mechanic", "welder", "data entry operator", "clerk",
            "home maker", "housewife", "unemployed", "retired"
        ]

        self.patterns = {
            'age_between': r'(?:age(?:d)?\s*(?:of)?\s*)?(?:between|from)\s*(\d{1,3})\s*(?:-|–|—|\sto\s|and)\s*(\d{1,3})',
            'age_simple_range': r'(\d{1,3})\s*(?:-|–|—)\s*(\d{1,3})\s*(?:years?)?',
            'age_min': r'(?:age\s*|applicant\s*|applicants\s*|applicant\'s\s*)?(?:over|above|at least|>=)\s*(\d{1,3})',
            'age_max': r'(?:age\s*|applicant\s*|applicants\s*|applicant\'s\s*)?(?:under|below|less than|<=|not exceeding)\s*(\d{1,3})',
            
            'income_max': r'(?:family\'s\s+|annual\s+|annual\s+family\s+|family\s+annual\s+)?(?:income|earnings|annual income|family income|total family income)\s*(?:should be|should not exceed|should not be more than|should be less than|is|are|:)?\s*(?:less than|below|under|not exceeding)?\s*(?:₹|Rs\.?|INR)?\s*([\d,]+(?:\.\d+)?)\s*(?:lakh|lakhs|lacs|thousand|k|per annum|per year|/year|pa|p\.a\.|annum)?',
            'income_min': r'(?:income|earnings|annual income|family income)\s*(?:should be|should exceed|must be|more than|over)\s*(?:₹|Rs\.?|INR)?\s*([\d,]+(?:\.\d+)?)',
            
            'gender_keywords': r'\b(women|woman|female|widow|widows|men|man|male)\b',
            
            'state_regex': r'\bresident\s+(?:of|in)?\s+([A-Z]?[a-zA-Z0-9&\-\s]+?)(?:[\.\n,;]|$)',
            
            'not_eligible_for': r'([A-Za-z0-9\s\-\&]+?)\s+(?:are|is|were|being|be)\s+not\s+eligible|not\s+eligible\s+for\s+([A-Za-z0-9\s\-\&]+)',
            
            'caste_sc': r'\b(sc|scheduled\s+caste|scheduled\s+castes)\b',
            'caste_st': r'\b(st|scheduled\s+tribe|scheduled\s+tribes)\b',
            'caste_obc': r'\b(obc|other\s+backward\s+class|backward\s+class)\b',
            'caste_general': r'\b(general|unreserved|ur)\b'
        }

        job_pattern = '|'.join(re.escape(job) for job in self.INDIAN_JOBS)
        self.patterns['occupation_regex'] = r'\b(' + job_pattern + r')(?:s)?\b'

        self.compiled_patterns = {k: re.compile(v, re.IGNORECASE) for k, v in self.patterns.items()}

    def _clean_amount(self, amt_str):
        if amt_str is None: return None
        s = str(amt_str).replace(',', '').strip()
        try:
            if '.' in s: return float(s)
            return int(s)
        except ValueError: return None

    def _parse_age(self, text: str) -> List[dict]:
        rules = []
        m = self.compiled_patterns['age_between'].search(text)
        if m:
            a = self._clean_amount(m.group(1)); b = self._clean_amount(m.group(2))
            if a is not None and b is not None:
                rules.append({"field": "age", "op": ">=", "value": int(a)})
                rules.append({"field": "age", "op": "<=", "value": int(b)})
                return rules
        m = self.compiled_patterns['age_simple_range'].search(text)
        if m:
            a = self._clean_amount(m.group(1)); b = self._clean_amount(m.group(2))
            if a is not None and b is not None:
                rules.append({"field": "age", "op": ">=", "value": int(a)})
                rules.append({"field": "age", "op": "<=", "value": int(b)})
                return rules
        m = self.compiled_patterns['age_min'].search(text)
        if m:
            a = self._clean_amount(m.group(1))
            if a is not None: rules.append({"field": "age", "op": ">=", "value": int(a)})
        m = self.compiled_patterns['age_max'].search(text)
        if m:
            a = self._clean_amount(m.group(1))
            if a is not None: rules.append({"field": "age", "op": "<=", "value": int(a)})
        return rules

    def _parse_income(self, text: str) -> List[dict]:
        rules = []
        m = self.compiled_patterns['income_max'].search(text)
        if m:
            amt = self._clean_amount(m.group(1))
            if amt is not None: rules.append({"field": "income", "op": "<=", "value": amt})
        m = self.compiled_patterns['income_min'].search(text)
        if m:
            amt = self._clean_amount(m.group(1))
            if amt is not None: rules.append({"field": "income", "op": ">=", "value": amt})
        return rules

    def _normalize_token(self, s: str) -> str:
        s = s.lower().strip()
        s = re.sub(r'\s+state$', '', s, flags=re.IGNORECASE).strip()
        if s.endswith('s') and len(s) > 3: s = s[:-1]
        return s

    def _parse_caste(self, text: str) -> List[dict]:
        castes_found = set()
        if self.compiled_patterns['caste_sc'].search(text): castes_found.add("Scheduled Caste (SC)")
        if self.compiled_patterns['caste_st'].search(text): castes_found.add("Scheduled Tribe (ST)")
        if self.compiled_patterns['caste_obc'].search(text): castes_found.add("Other Backward Classes (OBC)")
        if self.compiled_patterns['caste_general'].search(text): castes_found.add("General/Unreserved")
        
        if castes_found:
            return [{"field": "caste", "op": "in", "value": list(castes_found)}]
        return []

    def _parse_categorical(self, text: str) -> List[dict]:
        rules = []

        excluded = set()
        for m in self.compiled_patterns['not_eligible_for'].finditer(text):
            group = (m.group(1) or m.group(2) or "").strip()
            if not group: continue
            parts = re.split(r',|\band\b', group, flags=re.IGNORECASE)
            for part in parts:
                norm = self._normalize_token(part)
                if norm: excluded.add(norm)

        occs = self.compiled_patterns['occupation_regex'].findall(text)
        occ_norms = sorted({self._normalize_token(o) for o in occs if o})
        positive_occs = [o for o in occ_norms if o not in excluded]
        if positive_occs:
            rules.append({"field": "occupation", "op": "in", "value": positive_occs})
        if excluded:
            rules.append({"field": "occupation", "op": "not_in", "value": sorted(list(excluded))})

        genders = self.compiled_patterns['gender_keywords'].findall(text)
        if genders:
            lowered = [g.lower() for g in genders]
            if any(k in lowered for k in ('female', 'women', 'woman', 'widow', 'widows')):
                rules.append({"field": "gender", "op": "==", "value": "female"})
            elif any(k in lowered for k in ('male', 'men', 'man')):
                rules.append({"field": "gender", "op": "==", "value": "male"})

        loc = self.compiled_patterns['state_regex'].search(text)
        if loc:
            location = loc.group(1).strip()
            location = re.sub(r'\s+state$', '', location, flags=re.IGNORECASE).strip()
            rules.append({"field": "state", "op": "in", "value": [location]})

        return rules

    def parse_text(self, text: str):
        original_text = text
        text = text.strip()
        conditions = []
        confidence = 1.0

        conditions.extend(self._parse_age(text))
        conditions.extend(self._parse_income(text))
        conditions.extend(self._parse_categorical(text))
        conditions.extend(self._parse_caste(text)) # Add caste parsing

        if not conditions:
            confidence = 0.0

        rule_structure = {"all": conditions}
        return rule_structure, confidenceimport sys
import os
from importlib import import_module

script_folder = os.path.dirname(os.path.abspath(__file__))
sys.path.insert(0, script_folder)

def fetch_all():
    print("fetching HTML")
    try:
        fetcher = import_module("fetcher")
    except Exception as e:
        print("Error: Could not import fetcher.py")
        print(e)
        sys.exit(1)

    fetcher.main()
    print("fetching completed.\n")


def parser_start():
    print("p arsing HTML")
    try:
        parser = import_module("parser")
    except Exception as e:
        print("Error: Could not import parser.py")
        print(e)
        sys.exit(1)

    parser.parse_all_html()
    print("Parsing completed.\n")


def main():
    fetch_all()
    parser_start()

if __name__ == "__main__":
    main()
import os
import sys
import importlib.util
from db import db
from models import Scheme, SchemeRule
from rule_parser import RuleParser

def load_scraped_schemes():
    current_dir = os.path.dirname(os.path.abspath(__file__))
    output_file_path = os.path.join(current_dir, 'output', 'sample_schemes.py')

    if not os.path.exists(output_file_path):
        print(f"Warning: Scraped data file not found at {output_file_path}")
        print("Please run 'runner.py' inside the webapp folder first.")
        return []

    try:
        spec = importlib.util.spec_from_file_location("scraped_data", output_file_path)
        scraped_module = importlib.util.module_from_spec(spec)
        spec.loader.exec_module(scraped_module)
        
        if hasattr(scraped_module, 'SAMPLE_SCHEMES'):
            schemes = scraped_module.SAMPLE_SCHEMES
            return schemes
        else:
            print("Error: SAMPLE_SCHEMES list not found in the generated file.")
            return []
    except Exception as e:
        print(f"Error loading scraped data: {e}")
        return []

def ensure_sample_data():
    if Scheme.query.count() > 0:
        return

    print("Starting Data seed")
    raw_inputs = load_scraped_schemes()
    
    if not raw_inputs:
        print("No data found to insert.")
        return
    parser = RuleParser()
    
    count = 0
    for item in raw_inputs:
        title = item.get('title', 'Unknown Scheme')
        raw_text = item.get('description', '') 
        source_url = item.get('source_url', '')
        scraped_state = item.get('state', '')

        if not raw_text or len(raw_text) < 10:
            print(f"Skipping '{title}': Insufficient description text for parsing.")
            continue

        print(f"Processing: {title}...")

        rule_json, confidence = parser.parse_text(raw_text)

        detected_state = scraped_state
        
        for rule in rule_json.get('all', []):
            if rule.get('field') == 'state' and rule.get('op') == 'in':
                if rule.get('value'):
                    detected_state = rule['value'][0].title() 
                    break

        scheme = Scheme(
            title=title,
            description=raw_text, 
            state=detected_state, 
            source_url=source_url
        )
        
        db.session.add(scheme)
        db.session.flush() 

        scheme_rule = SchemeRule(
            scheme_id=scheme.id,
            rule_json=rule_json,
            snippet=raw_text[:500],
            parser_confidence=confidence,
            verified=False 
        )
        db.session.add(scheme_rule)
        count += 1

    db.session.commit()
    print(f"--- Successfully Inserted {count} Schemes ---")